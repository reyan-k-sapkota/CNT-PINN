{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72edc91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "\n",
    "df = pd.read_csv('../CNt_Reinforced_Concrete_Final_Dataset.csv')\n",
    "target_col = 'Compressive strength (MPa)'\n",
    "feature_cols = [c for c in df.columns if c != target_col] # getting remaining columns\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize to [-1, 1] for stable GAN training. \n",
    "\n",
    "X_mean, X_std = X.mean(0), X.std(0)\n",
    "y_mean, y_std = y.mean(0), y.std(0)\n",
    "\n",
    "X_norm = (X - X_mean) / (X_std + 1e-8)\n",
    "y_norm = (y - y_mean) / (y_std + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 WGAN-GP Model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=32, out_dim=9):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, out_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, in_dim=9):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Hyper‑params #These will be tuned accordingly\n",
    "NOISE_DIM = 32\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "CRITIC_ITER = 5\n",
    "LAMBDA_GP = 10\n",
    "LR = 1e-4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "G = Generator(NOISE_DIM, X.shape[1] + 1).to(device)\n",
    "C = Critic(X.shape[1] + 1).to(device)\n",
    "\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=LR, betas=(0.0, 0.9))\n",
    "opt_C = torch.optim.Adam(C.parameters(), lr=LR, betas=(0.0, 0.9))\n",
    "\n",
    "# DataLoader\n",
    "dataset = TensorDataset(torch.tensor(np.c_[X_norm, y_norm], dtype=torch.float32))\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Gradient penalty\n",
    "def gradient_penalty(critic, real, fake):\n",
    "    alpha = torch.rand(real.size(0), 1, device=device)\n",
    "    interp = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\n",
    "    d_interp = critic(interp)\n",
    "    grad = torch.autograd.grad(\n",
    "        d_interp, interp, torch.ones_like(d_interp),\n",
    "        create_graph=True, retain_graph=True\n",
    "    )[0]\n",
    "    return ((grad.norm(2, dim=1) - 1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for i, (real_batch,) in enumerate(loader):\n",
    "        real_batch = real_batch.to(device)\n",
    "\n",
    "        # Update Critic\n",
    "        for _ in range(CRITIC_ITER):\n",
    "            noise = torch.randn(real_batch.size(0), NOISE_DIM, device=device)\n",
    "            fake_batch = G(noise)\n",
    "            d_real = C(real_batch)\n",
    "            d_fake = C(fake_batch.detach())\n",
    "            gp = gradient_penalty(C, real_batch, fake_batch)\n",
    "            loss_C = d_fake.mean() - d_real.mean() + LAMBDA_GP * gp\n",
    "\n",
    "            opt_C.zero_grad()\n",
    "            loss_C.backward()\n",
    "            opt_C.step()\n",
    "\n",
    "        # Update Generator\n",
    "        noise = torch.randn(real_batch.size(0), NOISE_DIM, device=device)\n",
    "        fake_batch = G(noise)\n",
    "        loss_G = -C(fake_batch).mean()\n",
    "        opt_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}  loss_C={loss_C.item():.4f}  loss_G={loss_G.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27298baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Generate and de‑normalize synthetic data (≈2× original size)\n",
    "\n",
    "G.eval()\n",
    "n_synth = 2 * len(df)  # ≈ 600 rows\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(n_synth, NOISE_DIM, device=device)\n",
    "    synth_norm = G(z).cpu().numpy()\n",
    "\n",
    "synth_X = synth_norm[:, :-1] * (X_std + 1e-8) + X_mean\n",
    "synth_y = synth_norm[:, -1:] * (y_std + 1e-8) + y_mean\n",
    "\n",
    "synth_df = pd.DataFrame(np.c_[synth_X, synth_y], columns=df.columns)\n",
    "\n",
    "# Save\n",
    "synth_df.to_csv('../CNT_Concrete_Synth_Wgan.csv', index=False)\n",
    "print(f'Saved as CNT_Concrete_Synth_Wgan.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c96f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. DECISION METRICS . To check if the augmented data is suitable for usage\n",
    "\n",
    "\n",
    "def evaluate_augmentation(real, synth, target):\n",
    "    \"\"\"\n",
    "    Returns a dict of metrics (lower = more similar / better).\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # 1. Marginal statistics (mean & std distance)\n",
    "    for col in real.columns:\n",
    "        r, s = real[col], synth[col]\n",
    "        metrics[f'dmean_{col}'] = abs(r.mean() - s.mean())\n",
    "        metrics[f'dstd_{col}']  = abs(r.std()  - s.std())\n",
    "\n",
    "\n",
    "\n",
    "    # 2. Kolmogorov‑Smirnov distance (distribution similarity)\n",
    "    for col in real.columns:\n",
    "        ks_stat, _ = stats.ks_2samp(real[col], synth[col])\n",
    "        metrics[f'KS_{col}'] = ks_stat\n",
    "\n",
    "    # 3. Pairwise correlation preservation\n",
    "    corr_real = real.corr().values\n",
    "    corr_synth = synth.corr().values\n",
    "    corr_mse = np.mean((corr_real - corr_synth) ** 2)\n",
    "    metrics['corr_mse'] = corr_mse\n",
    "\n",
    "    # 4. Predictive utility (most important)\n",
    "    # Train a simple RF on synthetic data, test on real data\n",
    "    X_real = real.drop(columns=[target])\n",
    "    y_real = real[target]\n",
    "    X_synth = synth.drop(columns=[target])\n",
    "    y_synth = synth[target]\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_synth, y_synth)\n",
    "    preds = rf.predict(X_real)\n",
    "    metrics['pred_r2_on_real'] = r2_score(y_real, preds)\n",
    "    metrics['pred_rmse_on_real'] = root_mean_squared_error(y_real, preds, squared=False)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Run evaluation\n",
    "score = evaluate_augmentation(df, synth_df, target_col)\n",
    "\n",
    "print('\\n QUALITY DECISION METRICS ')\n",
    "\n",
    "for k, v in score.items():\n",
    "    print(f'{k:<20}  {v:.5f}')\n",
    "\n",
    "# Suggested thresholds\n",
    "good_enough = (\n",
    "    score['pred_r2_on_real'] > 0.5 and\n",
    "    score['corr_mse'] < 0.5 and\n",
    "    all(score[f'KS_{c}'] < 0.3 for c in df.columns)\n",
    ")\n",
    "\n",
    "if good_enough:\n",
    "    print(\"OKAY\")\n",
    "else:\n",
    "    print(\"NOT OKAY\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WQI_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
